{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create uninitialized tensor\n",
    "x = torch.Tensor(5, 3)\n",
    "# create initilalized tensor\n",
    "y = torch.ones(5)\n",
    "z = torch.zeros(5)\n",
    "\n",
    "# addition\n",
    "x = torch.add(y, z)\n",
    "torch.add(y, z, out=x)\n",
    "\n",
    "# modify in place - any function that modifies has a trailing _\n",
    "x.add_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.DoubleTensor of size 5]\n",
      " [ 2.  2.  2.  2.  2.]\n",
      "\n",
      " 6\n",
      " 6\n",
      " 6\n",
      "[torch.FloatTensor of size 3]\n",
      " [ 6.  6.  6.]\n"
     ]
    }
   ],
   "source": [
    "# moving to and from numpy - they still share the same memory\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "b.add_(1)\n",
    "print(b, a)\n",
    "\n",
    "c = torch.ones(3)\n",
    "d = c.numpy()\n",
    "d += 5\n",
    "print(c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "\n",
      " 8\n",
      " 8\n",
      " 8\n",
      " 8\n",
      " 8\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# do we have a GPU?\n",
    "print(torch.cuda.is_available())\n",
    "x = torch.ones(5)\n",
    "y = torch.zeros(5) + 7\n",
    "\n",
    "# move things onto the GPU (this will fail if we don't have a GPU I think)\n",
    "x.cuda()\n",
    "y.cuda()\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      " 3  3\n",
      " 3  3\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      " 27  27\n",
      " 27  27\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      " 27\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.5000  4.5000\n",
      " 4.5000  4.5000\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Variable \"Wraps a tensor and records the operations applied to it.\"\n",
    "# http://pytorch.org/docs/0.3.0/autograd.html#torch.autograd.Variable\n",
    "x = Variable(torch.ones(2, 2), requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x + 2\n",
    "print(y)\n",
    "\n",
    "z = y * y * 3\n",
    "print(z)\n",
    "\n",
    "out = z.mean()\n",
    "print(out)\n",
    "\n",
    "# Variable.backward \"Computes the gradient of current variable w.r.t. graph leaves.\"\n",
    "# http://pytorch.org/docs/0.3.0/autograd.html#torch.autograd.Variable.backward\n",
    "out.backward()\n",
    "print(x.grad) # d(out)/dx. Note that you can't do this for y or z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Variable containing:\n",
      " 378.0182\n",
      " 807.5120\n",
      "-659.2539\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "  51.2000\n",
      " 512.0000\n",
      "   0.0512\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3)\n",
    "x = Variable(x, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "n = 1\n",
    "while y.data.norm() < 1000:\n",
    "    n += 1\n",
    "    y = y * 2\n",
    "\n",
    "print(n)\n",
    "print(y)\n",
    "# y = 2^n * x\n",
    "# dy/dx = 2^n\n",
    "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "y.backward(gradients)\n",
    "# x.grad = 2^n scaled by the tensor we passed to y.backward. Unclear why we do this\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "Convolutions, pooling, non-linear activation layers (relu?), linear, loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: Parameter containing:\n",
      "-0.2793 -0.5173 -0.2821\n",
      "-0.3767 -0.1036  0.0083\n",
      "-0.3715  0.1794  0.2099\n",
      "-0.0109 -0.4441  0.1441\n",
      " 0.1493  0.4208 -0.2435\n",
      "[torch.cuda.FloatTensor of size 5x3 (GPU 0)]\n",
      "\n",
      "Bias: Parameter containing:\n",
      " 0.2942\n",
      " 0.1223\n",
      " 0.4086\n",
      "-0.5541\n",
      " 0.2998\n",
      "[torch.cuda.FloatTensor of size 5 (GPU 0)]\n",
      "\n",
      "Input: Variable containing:\n",
      " 1.3291  1.2303  0.3277\n",
      " 1.0239 -1.3926 -1.4749\n",
      "[torch.cuda.FloatTensor of size 2x3 (GPU 0)]\n",
      "\n",
      "Output: Variable containing:\n",
      "-0.8058 -0.5030  0.2043 -1.0677  0.9360\n",
      " 1.1446 -0.1314 -0.5313 -0.1594  0.2258\n",
      "[torch.cuda.FloatTensor of size 2x5 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear\n",
    "m = nn.Linear(3, 5).cuda()\n",
    "print(\"Weight:\", m.weight)\n",
    "print(\"Bias:\", m.bias)\n",
    "\n",
    "inp = autograd.Variable(torch.randn(2, 3)).cuda()\n",
    "print(\"Input:\", inp)\n",
    "\n",
    "out = m(inp)\n",
    "print(\"Output:\", out)\n",
    "\n",
    "# out = m.weight * inp + m.bias; note that weight is a 5x3 and bias is a 5x1 so that \n",
    "# (weight) 5x3 * 3x1 = 5x1 + (bias) 5x1 = 5x1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29253748000000007"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4131*0.4569 + 0.26*-1.0166 + 0.2009*-0.6799 + 0.5047"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 4])\n",
      "torch.Size([3])\n",
      "torch.Size([2, 1, 8])\n",
      "torch.Size([2, 3, 5])\n",
      "Variable containing:\n",
      " 0.0617  0.2367  0.2365 -0.0008\n",
      "[torch.FloatTensor of size 1x4]\n",
      "\n",
      "Variable containing:\n",
      "-0.4776\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 2.7438  0.8303 -1.1472 -0.6355  1.9833  0.7237  0.7010  1.3415\n",
      "[torch.FloatTensor of size 1x8]\n",
      "\n",
      "Variable containing:\n",
      "-0.3826 -0.8497 -0.2304  0.1231 -0.0193\n",
      "-0.6302  0.0546  0.9190  1.0034  0.7299\n",
      "-0.1047 -0.3683 -1.1348 -0.6199 -0.8037\n",
      "[torch.FloatTensor of size 3x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Conv1d(in_channels, out_channels, kernel_size)\n",
    "# \"channel\" is ~ attribute of data\n",
    "# 1 channel - grayscale image. 2 channels - height and weight of person. 3 channels - RGB image\n",
    "# 1d here means that the vector is 1d (just has a length)\n",
    "# This mostly just changes the number of channels, but also changes the size of the data based off how many\n",
    "# full convolutions it can fit\n",
    "m = nn.Conv1d(1, 3, 4)\n",
    "print(m.weight.shape)\n",
    "print(m.bias.shape)\n",
    "# 2 variables that have 1 channel of 8 items\n",
    "x = torch.randn(2, 1, 8)\n",
    "\n",
    "inp = autograd.Variable(x)\n",
    "print(inp.shape)\n",
    "out = m(inp)\n",
    "print(out.shape)\n",
    "\n",
    "print(m.weight[0])\n",
    "print(m.bias[0])\n",
    "print(inp[0])\n",
    "print(out[0])\n",
    "#print(m.weight[0][:4].numpy * inp[0][:4] + bias[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.52716006"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4497*1.0882 + -0.2141*0.0440 + -0.1572*-1.5311 + -0.3080*-1.0910 + 0.4705"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
